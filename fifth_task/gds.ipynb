{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AZP5j7NBSxm"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUZmQ8jYBSxt"
   },
   "source": [
    "### Random matrix generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need matrix of our quadratic function to be positive definite. The definition is: \n",
    "\n",
    "$$ M \\text { positive definite } \\Longleftrightarrow x^{\\top} M x>0 \\text { for all } x \\in \\mathbb{R}^{n} \\backslash \\mathbf{0} $$\n",
    "\n",
    "And we know that matrix is p.d. if and only if all of it's eigenvalues are positive. So i have a little function that check if matrix is p.d. Actually we don't really need this, becouse if we create our matrix as $A=A*A^T$ we will definitely get symmetric and p.d. matrix (1-st is obvious, 2-nd is becouse <a href=\"https://en.wikipedia.org/wiki/Cholesky_decomposition\">Cholesky decomposition</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IY7_vd2rBSxw"
   },
   "outputs": [],
   "source": [
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZUcZ14FBSx2"
   },
   "outputs": [],
   "source": [
    "n = 3 # size \n",
    "\n",
    "A = np.random.rand(n, n)\n",
    "A = A@A.T\n",
    "\n",
    "while not is_pos_def(A):\n",
    "    A = np.random.rand(n, n)\n",
    "    A = A@A.T\n",
    "b = np.random.rand(n, 1)\n",
    "\n",
    "eps = 1e-6 # precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZh-mFr-BSx5",
    "outputId": "4419139a-8f3b-46f0-d60f-8ae8146d0fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.49077028 1.47877834 1.2775005 ]\n",
      " [1.47877834 1.92387993 1.64779715]\n",
      " [1.2775005  1.64779715 1.66452232]]\n",
      "[[0.89789178]\n",
      " [0.38259099]\n",
      " [0.07012672]]\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x)=\\frac{1}{2} x^{T} A x+x^{T} b$$\n",
    "\n",
    "We need result to be scalar, but numpy will give as array. So we use np.asscalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYZE0ti5BSx_"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.asscalar(1/2*x.T@A@x + b.T@x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0rTgB5LQBSyB"
   },
   "source": [
    "### Steepest gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theory behind this is simple. Let imagine that we have $x^k$ and we want to build $x^{k+1}$ that $f(x^{k+1}) < f(x^k)$. Let $x^{k+1} = x^k+\\mu q$. So $q$ is direction, $\\mu$ is step size. We can use condition on global minimum to find $\\mu$. For our simple and convinient function it sounds like: $\\dot{f}(x)=0$. So \n",
    "$$\\begin{aligned} f\\left(x^{k+1}\\right) &=f\\left(x^{k}+\\mu q\\right) \\equiv \\varphi(\\mu)=\\varphi(0)+\\mu \\dot{\\varphi}(0)+\\frac{1}{2} \\mu^{2} \\ddot{\\varphi}(0), \\quad \\dot{\\varphi}=\\frac{d \\varphi}{d \\mu} \\end{aligned}$$\n",
    "Where \n",
    "$$\\varphi(0)=f\\left(x^{k}\\right), \\dot{\\varphi}(0)=q^{T}\\left(A x^{k}+b\\right), \\ddot{\\varphi}(0)=q^{T} A q$$\n",
    "And finally \n",
    "$$\\bar{\\mu}_{k}=-\\frac{\\dot{\\varphi}(0)}{\\ddot{\\varphi}(0)}=-\\frac{q^{T}\\left(A x^{k}+b\\right)}{q^{T} \\cdot A q}$$\n",
    "\n",
    "We build our ${x^{k+1}}$ using this formulas and get decreasing sequence for $f(x)$. And eventually we get our extrema \n",
    "\n",
    "The only thing left is direction of descent. And this is the only part that differ Gradient descent and Coordinate descent. \n",
    "\n",
    "In sgd we can take gradient of our function ($\\operatorname{grad} f(x)=\\left(\\frac{\\partial f(x)}{\\partial x_{1}}, \\frac{\\partial f(x)}{\\partial x_{2}}, \\dots \\frac{\\partial f(x)}{\\partial x_{n}}\\right)^{T}$), in our case it would be $q=\\operatorname{grad} f(x)=A x+b$\n",
    "\n",
    "In cd we can take $q=e^{i}=(\\underbrace{0,0, \\ldots, 0,1}_{i}, 0 \\ldots, 0)^{T}$ where $e^i$ - i-th unit vector in our vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd():\n",
    "    x = b # init approximation \n",
    "    i = 0 # count \n",
    "\n",
    "    while True:\n",
    "        q = A@x + b # grad \n",
    "\n",
    "        mu = q.T @ q / (q.T @ A @ q)\n",
    "\n",
    "        x_old = x\n",
    "        x = x - np.asscalar(mu) * q\n",
    "\n",
    "        i += 1\n",
    "        if((np.linalg.norm(x - x_old) < eps and np.linalg.norm(q) < eps) or i > 1000000):\n",
    "            break\n",
    "    return x, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAJ_L8FfBSyB"
   },
   "outputs": [],
   "source": [
    "x_sd, i_sd = sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-f5ntUBKBSyC",
    "outputId": "238c42ec-b5b1-4c81-dd07-b3cf17678112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.73885235],\n",
       "        [ 0.20210461],\n",
       "        [ 1.09234411]]), 42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sd, i_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Pb6jjugBSyD",
    "outputId": "2dc04fa1-8e77-44d5-f470-a1ec555aa882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7036877250494035"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uhwTy0wBSyE"
   },
   "source": [
    "### Coordinate descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8y9gO4KBSyE"
   },
   "source": [
    "E - is utility matrix that allow us to extract unit vectors from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFx3Ops2BSyF",
    "outputId": "c80101b6-8eaf-410c-fc4f-0a37fe46c53a"
   },
   "outputs": [],
   "source": [
    "E = np.eye(n) \n",
    "E = np.matrix(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cd():\n",
    "    x = b\n",
    "    i = 0\n",
    "\n",
    "    while True: \n",
    "        for j in range(n):\n",
    "            q = E[j].T\n",
    "            mu = q.T @ (A@x+ b) / A[j][j]\n",
    "            \n",
    "            x_old = x\n",
    "            x = x - np.asscalar(mu) * q\n",
    "            \n",
    "        i += 1\n",
    "        if((np.linalg.norm(x - x_old) < eps and np.linalg.norm(A@x+b) < eps) or i > 1000000):\n",
    "            break\n",
    "    return x, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_YKuaZcBSyG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_coord, i_coord = cd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dhb0O-FBSyG",
    "outputId": "19be6978-8919-40cc-adab-93c08981221b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[-1.73885632],\n",
       "         [ 0.20210997],\n",
       "         [ 1.09234154]]), 76)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_coord, i_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAIvZWZnBSyH",
    "outputId": "f9b9ae87-d9b0-4a6f-9f26-a4754a3dd2ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7036877250469962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wKMd4bfBSyI"
   },
   "source": [
    "### Gaussian elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it is a well known algorithm in linear algebra for soloving systems of linear equations (<a href=\"https://en.wikipedia.org/wiki/Gaussian_elimination\">link</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BGzmtf4BSyI"
   },
   "outputs": [],
   "source": [
    "def gaus(A, b):\n",
    "    n = A.shape[0]\n",
    "    for i in range(n):\n",
    "        b[i] = b[i] / A[i][i]\n",
    "        A[i] = A[i] / A[i][i]\n",
    "        for j in range(i + 1, n):\n",
    "            b[j] = b[j] - A[j][i] * b[i]\n",
    "            A[j] = A[j] - A[j][i] * A[i]\n",
    "\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        for j in range(i - 1, -1, -1):\n",
    "            b[j] -= b[i] * A[j][i]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ElbmVGeBSyI"
   },
   "outputs": [],
   "source": [
    "x_pr = gaus(A.copy(), -b.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_SfFjfZBSyJ",
    "outputId": "d6010a41-7a0f-42ff-897b-cb952fd94e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73885285],\n",
       "       [ 0.20210564],\n",
       "       [ 1.09234316]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VoId82D3BSyK",
    "outputId": "13ab6bf9-2ba7-4e80-dec2-6cfbc33cbee3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7036877250495972"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5K5z76rXBSyK"
   },
   "source": [
    "### Comparison of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCtd5V-lBSyL"
   },
   "source": [
    "#### gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbkFm5foBSyL",
    "outputId": "0980973b-08da-413e-b768-36087913ee35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancy with the exact answer:  1.489369692730216e-06\n",
      "number of steps:  42\n"
     ]
    }
   ],
   "source": [
    "print(\"Discrepancy with the exact answer: \", np.linalg.norm(x_sd - x_pr))\n",
    "print(\"number of steps: \", i_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PSVq31s9BSyM"
   },
   "source": [
    "#### coordinate descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYSJUiJ8BSyM",
    "outputId": "761dc671-a3a1-4661-8b4a-3175268c2edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancy with the exact answer:  5.7788631503617155e-06\n",
      "number of steps:  76\n"
     ]
    }
   ],
   "source": [
    "print(\"Discrepancy with the exact answer: \", np.linalg.norm(x_coord - x_pr))\n",
    "print(\"number of steps: \", i_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "gds.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
